{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9c9c90",
   "metadata": {},
   "source": [
    "### Part 1: Tokenization and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1671490",
   "metadata": {},
   "source": [
    "- Import the nltk module\n",
    "- Select a text file or excerpt to work with (e.g. a paragraph from a book, a news arEcle, etc.)\n",
    "- Tokenize the text using nltk's word_tokenize() and sentence_tokenize() funcEons\n",
    "- Normalize the tokens by converEng them to lowercase and stemming using nltk's PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "950ded8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. The goal is a computer capable of 'understanding' the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\n",
      "\n",
      "Tokenization by Word:\n",
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'an', 'interdisciplinary', 'subfield', 'of', 'computer', 'science', 'and', 'linguistics', '.', 'It', 'is', 'primarily', 'concerned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'support', 'and', 'manipulate', 'human', 'language', '.', 'It', 'involves', 'processing', 'natural', 'language', 'datasets', ',', 'such', 'as', 'text', 'corpora', 'or', 'speech', 'corpora', ',', 'using', 'either', 'rule-based', 'or', 'probabilistic', '(', 'i.e', '.', 'statistical', 'and', ',', 'most', 'recently', ',', 'neural', 'network-based', ')', 'machine', 'learning', 'approaches', '.', 'The', 'goal', 'is', 'a', 'computer', 'capable', 'of', \"'understanding\", \"'\", 'the', 'contents', 'of', 'documents', ',', 'including', 'the', 'contextual', 'nuances', 'of', 'the', 'language', 'within', 'them', '.', 'The', 'technology', 'can', 'then', 'accurately', 'extract', 'information', 'and', 'insights', 'contained', 'in', 'the', 'documents', 'as', 'well', 'as', 'categorize', 'and', 'organize', 'the', 'documents', 'themselves', '.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'speech', 'recognition', ',', 'natural-language', 'understanding', ',', 'and', 'natural-language', 'generation', '.']\n",
      "\n",
      "Tokenization by Sentence:\n",
      "['Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics.', 'It is primarily concerned with giving computers the ability to support and manipulate human language.', 'It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e.', 'statistical and, most recently, neural network-based) machine learning approaches.', \"The goal is a computer capable of 'understanding' the contents of documents, including the contextual nuances of the language within them.\", 'The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.', 'Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.']\n",
      "\n",
      "Normalized Tokens (Lowercase and Stemmed):\n",
      "['natur', 'languag', 'process', '(', 'nlp', ')', 'is', 'an', 'interdisciplinari', 'subfield', 'of', 'comput', 'scienc', 'and', 'linguist', '.', 'it', 'is', 'primarili', 'concern', 'with', 'give', 'comput', 'the', 'abil', 'to', 'support', 'and', 'manipul', 'human', 'languag', '.', 'it', 'involv', 'process', 'natur', 'languag', 'dataset', ',', 'such', 'as', 'text', 'corpora', 'or', 'speech', 'corpora', ',', 'use', 'either', 'rule-bas', 'or', 'probabilist', '(', 'i.e', '.', 'statist', 'and', ',', 'most', 'recent', ',', 'neural', 'network-bas', ')', 'machin', 'learn', 'approach', '.', 'the', 'goal', 'is', 'a', 'comput', 'capabl', 'of', \"'understand\", \"'\", 'the', 'content', 'of', 'document', ',', 'includ', 'the', 'contextu', 'nuanc', 'of', 'the', 'languag', 'within', 'them', '.', 'the', 'technolog', 'can', 'then', 'accur', 'extract', 'inform', 'and', 'insight', 'contain', 'in', 'the', 'document', 'as', 'well', 'as', 'categor', 'and', 'organ', 'the', 'document', 'themselv', '.', 'challeng', 'in', 'natur', 'languag', 'process', 'frequent', 'involv', 'speech', 'recognit', ',', 'natural-languag', 'understand', ',', 'and', 'natural-languag', 'gener', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\karth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Select a text excerpt\n",
    "text = \"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. The goal is a computer capable of 'understanding' the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\"\n",
    "\n",
    "# Tokenize by word and sentence\n",
    "tokens_word = word_tokenize(text)\n",
    "tokens_sentence = sent_tokenize(text)\n",
    "\n",
    "# Normalize tokens by converting to lowercase\n",
    "tokens_word_lower = [word.lower() for word in tokens_word]\n",
    "\n",
    "# Stemming using PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "tokens_stemmed = [porter.stem(word) for word in tokens_word_lower]\n",
    "\n",
    "# Print the results\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "print(\"\\nTokenization by Word:\")\n",
    "print(tokens_word)\n",
    "print(\"\\nTokenization by Sentence:\")\n",
    "print(tokens_sentence)\n",
    "print(\"\\nNormalized Tokens (Lowercase and Stemmed):\")\n",
    "print(tokens_stemmed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e265995",
   "metadata": {},
   "source": [
    "### Part 2: Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c1896",
   "metadata": {},
   "source": [
    "- Use nltk's pos_tag() funcEon to tag each tokenized word with its part-of-speech\n",
    "- Examine the tagged words and take note of any paMerns, surprises or errors you see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "055fd72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. The goal is a computer capable of 'understanding' the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\n",
      "\n",
      "Part-of-Speech Tags:\n",
      "[('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('an', 'DT'), ('interdisciplinary', 'JJ'), ('subfield', 'NN'), ('of', 'IN'), ('computer', 'NN'), ('science', 'NN'), ('and', 'CC'), ('linguistics', 'NNS'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('primarily', 'RB'), ('concerned', 'VBN'), ('with', 'IN'), ('giving', 'VBG'), ('computers', 'NNS'), ('the', 'DT'), ('ability', 'NN'), ('to', 'TO'), ('support', 'VB'), ('and', 'CC'), ('manipulate', 'VB'), ('human', 'JJ'), ('language', 'NN'), ('.', '.'), ('It', 'PRP'), ('involves', 'VBZ'), ('processing', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('datasets', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('text', 'JJ'), ('corpora', 'NN'), ('or', 'CC'), ('speech', 'NN'), ('corpora', 'NNS'), (',', ','), ('using', 'VBG'), ('either', 'CC'), ('rule-based', 'JJ'), ('or', 'CC'), ('probabilistic', 'JJ'), ('(', '('), ('i.e', 'JJ'), ('.', '.'), ('statistical', 'JJ'), ('and', 'CC'), (',', ','), ('most', 'RBS'), ('recently', 'RB'), (',', ','), ('neural', 'JJ'), ('network-based', 'JJ'), (')', ')'), ('machine', 'NN'), ('learning', 'VBG'), ('approaches', 'NNS'), ('.', '.'), ('The', 'DT'), ('goal', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('computer', 'NN'), ('capable', 'NN'), ('of', 'IN'), (\"'understanding\", 'VBG'), (\"'\", \"''\"), ('the', 'DT'), ('contents', 'NNS'), ('of', 'IN'), ('documents', 'NNS'), (',', ','), ('including', 'VBG'), ('the', 'DT'), ('contextual', 'JJ'), ('nuances', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('language', 'NN'), ('within', 'IN'), ('them', 'PRP'), ('.', '.'), ('The', 'DT'), ('technology', 'NN'), ('can', 'MD'), ('then', 'RB'), ('accurately', 'RB'), ('extract', 'JJ'), ('information', 'NN'), ('and', 'CC'), ('insights', 'NNS'), ('contained', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('documents', 'NNS'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('categorize', 'NN'), ('and', 'CC'), ('organize', 'VB'), ('the', 'DT'), ('documents', 'NNS'), ('themselves', 'PRP'), ('.', '.'), ('Challenges', 'NNS'), ('in', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('frequently', 'RB'), ('involve', 'VBP'), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('natural-language', 'JJ'), ('understanding', 'NN'), (',', ','), ('and', 'CC'), ('natural-language', 'JJ'), ('generation', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Part-of-Speech Tagging\n",
    "pos_tags = nltk.pos_tag(tokens_word)\n",
    "\n",
    "# Print the results\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "print(\"\\nPart-of-Speech Tags:\")\n",
    "print(pos_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e2e51",
   "metadata": {},
   "source": [
    "### Part 3: N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2e7694",
   "metadata": {},
   "source": [
    "- Use ngrams() to create a series of bi-grams and tri-grams from the tokenized text\n",
    "- Calculate the frequency distribuEon of the n-grams using FreqDist()\n",
    "- Identify the most common bi-grams and tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6905be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bi-Grams:\n",
      "[('Natural', 'language'), ('language', 'processing'), ('processing', '('), ('(', 'NLP'), ('NLP', ')'), (')', 'is'), ('is', 'an'), ('an', 'interdisciplinary'), ('interdisciplinary', 'subfield'), ('subfield', 'of'), ('of', 'computer'), ('computer', 'science'), ('science', 'and'), ('and', 'linguistics'), ('linguistics', '.'), ('.', 'It'), ('It', 'is'), ('is', 'primarily'), ('primarily', 'concerned'), ('concerned', 'with'), ('with', 'giving'), ('giving', 'computers'), ('computers', 'the'), ('the', 'ability'), ('ability', 'to'), ('to', 'support'), ('support', 'and'), ('and', 'manipulate'), ('manipulate', 'human'), ('human', 'language'), ('language', '.'), ('.', 'It'), ('It', 'involves'), ('involves', 'processing'), ('processing', 'natural'), ('natural', 'language'), ('language', 'datasets'), ('datasets', ','), (',', 'such'), ('such', 'as'), ('as', 'text'), ('text', 'corpora'), ('corpora', 'or'), ('or', 'speech'), ('speech', 'corpora'), ('corpora', ','), (',', 'using'), ('using', 'either'), ('either', 'rule-based'), ('rule-based', 'or'), ('or', 'probabilistic'), ('probabilistic', '('), ('(', 'i.e'), ('i.e', '.'), ('.', 'statistical'), ('statistical', 'and'), ('and', ','), (',', 'most'), ('most', 'recently'), ('recently', ','), (',', 'neural'), ('neural', 'network-based'), ('network-based', ')'), (')', 'machine'), ('machine', 'learning'), ('learning', 'approaches'), ('approaches', '.'), ('.', 'The'), ('The', 'goal'), ('goal', 'is'), ('is', 'a'), ('a', 'computer'), ('computer', 'capable'), ('capable', 'of'), ('of', \"'understanding\"), (\"'understanding\", \"'\"), (\"'\", 'the'), ('the', 'contents'), ('contents', 'of'), ('of', 'documents'), ('documents', ','), (',', 'including'), ('including', 'the'), ('the', 'contextual'), ('contextual', 'nuances'), ('nuances', 'of'), ('of', 'the'), ('the', 'language'), ('language', 'within'), ('within', 'them'), ('them', '.'), ('.', 'The'), ('The', 'technology'), ('technology', 'can'), ('can', 'then'), ('then', 'accurately'), ('accurately', 'extract'), ('extract', 'information'), ('information', 'and'), ('and', 'insights'), ('insights', 'contained'), ('contained', 'in'), ('in', 'the'), ('the', 'documents'), ('documents', 'as'), ('as', 'well'), ('well', 'as'), ('as', 'categorize'), ('categorize', 'and'), ('and', 'organize'), ('organize', 'the'), ('the', 'documents'), ('documents', 'themselves'), ('themselves', '.'), ('.', 'Challenges'), ('Challenges', 'in'), ('in', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'frequently'), ('frequently', 'involve'), ('involve', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'natural-language'), ('natural-language', 'understanding'), ('understanding', ','), (',', 'and'), ('and', 'natural-language'), ('natural-language', 'generation'), ('generation', '.')]\n",
      "\n",
      "Tri-Grams:\n",
      "[('Natural', 'language', 'processing'), ('language', 'processing', '('), ('processing', '(', 'NLP'), ('(', 'NLP', ')'), ('NLP', ')', 'is'), (')', 'is', 'an'), ('is', 'an', 'interdisciplinary'), ('an', 'interdisciplinary', 'subfield'), ('interdisciplinary', 'subfield', 'of'), ('subfield', 'of', 'computer'), ('of', 'computer', 'science'), ('computer', 'science', 'and'), ('science', 'and', 'linguistics'), ('and', 'linguistics', '.'), ('linguistics', '.', 'It'), ('.', 'It', 'is'), ('It', 'is', 'primarily'), ('is', 'primarily', 'concerned'), ('primarily', 'concerned', 'with'), ('concerned', 'with', 'giving'), ('with', 'giving', 'computers'), ('giving', 'computers', 'the'), ('computers', 'the', 'ability'), ('the', 'ability', 'to'), ('ability', 'to', 'support'), ('to', 'support', 'and'), ('support', 'and', 'manipulate'), ('and', 'manipulate', 'human'), ('manipulate', 'human', 'language'), ('human', 'language', '.'), ('language', '.', 'It'), ('.', 'It', 'involves'), ('It', 'involves', 'processing'), ('involves', 'processing', 'natural'), ('processing', 'natural', 'language'), ('natural', 'language', 'datasets'), ('language', 'datasets', ','), ('datasets', ',', 'such'), (',', 'such', 'as'), ('such', 'as', 'text'), ('as', 'text', 'corpora'), ('text', 'corpora', 'or'), ('corpora', 'or', 'speech'), ('or', 'speech', 'corpora'), ('speech', 'corpora', ','), ('corpora', ',', 'using'), (',', 'using', 'either'), ('using', 'either', 'rule-based'), ('either', 'rule-based', 'or'), ('rule-based', 'or', 'probabilistic'), ('or', 'probabilistic', '('), ('probabilistic', '(', 'i.e'), ('(', 'i.e', '.'), ('i.e', '.', 'statistical'), ('.', 'statistical', 'and'), ('statistical', 'and', ','), ('and', ',', 'most'), (',', 'most', 'recently'), ('most', 'recently', ','), ('recently', ',', 'neural'), (',', 'neural', 'network-based'), ('neural', 'network-based', ')'), ('network-based', ')', 'machine'), (')', 'machine', 'learning'), ('machine', 'learning', 'approaches'), ('learning', 'approaches', '.'), ('approaches', '.', 'The'), ('.', 'The', 'goal'), ('The', 'goal', 'is'), ('goal', 'is', 'a'), ('is', 'a', 'computer'), ('a', 'computer', 'capable'), ('computer', 'capable', 'of'), ('capable', 'of', \"'understanding\"), ('of', \"'understanding\", \"'\"), (\"'understanding\", \"'\", 'the'), (\"'\", 'the', 'contents'), ('the', 'contents', 'of'), ('contents', 'of', 'documents'), ('of', 'documents', ','), ('documents', ',', 'including'), (',', 'including', 'the'), ('including', 'the', 'contextual'), ('the', 'contextual', 'nuances'), ('contextual', 'nuances', 'of'), ('nuances', 'of', 'the'), ('of', 'the', 'language'), ('the', 'language', 'within'), ('language', 'within', 'them'), ('within', 'them', '.'), ('them', '.', 'The'), ('.', 'The', 'technology'), ('The', 'technology', 'can'), ('technology', 'can', 'then'), ('can', 'then', 'accurately'), ('then', 'accurately', 'extract'), ('accurately', 'extract', 'information'), ('extract', 'information', 'and'), ('information', 'and', 'insights'), ('and', 'insights', 'contained'), ('insights', 'contained', 'in'), ('contained', 'in', 'the'), ('in', 'the', 'documents'), ('the', 'documents', 'as'), ('documents', 'as', 'well'), ('as', 'well', 'as'), ('well', 'as', 'categorize'), ('as', 'categorize', 'and'), ('categorize', 'and', 'organize'), ('and', 'organize', 'the'), ('organize', 'the', 'documents'), ('the', 'documents', 'themselves'), ('documents', 'themselves', '.'), ('themselves', '.', 'Challenges'), ('.', 'Challenges', 'in'), ('Challenges', 'in', 'natural'), ('in', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', 'frequently'), ('processing', 'frequently', 'involve'), ('frequently', 'involve', 'speech'), ('involve', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'natural-language'), (',', 'natural-language', 'understanding'), ('natural-language', 'understanding', ','), ('understanding', ',', 'and'), (',', 'and', 'natural-language'), ('and', 'natural-language', 'generation'), ('natural-language', 'generation', '.')]\n",
      "\n",
      "Most Common Bi-Grams:\n",
      "[(('language', 'processing'), 2), (('.', 'It'), 2), (('natural', 'language'), 2), (('.', 'The'), 2), (('the', 'documents'), 2)]\n",
      "\n",
      "Most Common Tri-Grams:\n",
      "[(('Natural', 'language', 'processing'), 1), (('language', 'processing', '('), 1), (('processing', '(', 'NLP'), 1), (('(', 'NLP', ')'), 1), (('NLP', ')', 'is'), 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Create bi-grams and tri-grams\n",
    "bi_grams = list(ngrams(tokens_word, 2))\n",
    "tri_grams = list(ngrams(tokens_word, 3))\n",
    "\n",
    "# Calculate frequency distribution\n",
    "fd_bi_grams = FreqDist(bi_grams)\n",
    "fd_tri_grams = FreqDist(tri_grams)\n",
    "\n",
    "# Identify most common bi-grams and tri-grams\n",
    "common_bi_grams = fd_bi_grams.most_common(5)\n",
    "common_tri_grams = fd_tri_grams.most_common(5)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nBi-Grams:\")\n",
    "print(bi_grams)\n",
    "print(\"\\nTri-Grams:\")\n",
    "print(tri_grams)\n",
    "print(\"\\nMost Common Bi-Grams:\")\n",
    "print(common_bi_grams)\n",
    "print(\"\\nMost Common Tri-Grams:\")\n",
    "print(common_tri_grams)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
